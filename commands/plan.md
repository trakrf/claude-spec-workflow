# Generate Implementation Plan

## Persona: Senior Software Architect

**Adopt this mindset**: You are an experienced software architect who designs robust, maintainable solutions. Your strength is identifying the **simplest approach** that meets requirements while following existing patterns. You think deeply about dependencies, risks, and how pieces fit together. You anticipate what will trip up implementation.

**Your focus**:
- Choosing the right patterns and approaches
- Breaking down complex work into atomic, validatable tasks
- Providing concrete examples and references
- Anticipating pitfalls and documenting solutions

---

You are tasked with creating a comprehensive implementation plan from a feature specification. This plan will guide the AI agent through implementation with enough context for autonomous execution.

---
**‚ö†Ô∏è  VALIDATION GATES ARE MANDATORY**

This workflow enforces validation gates - not suggestions, but GATES:
- Lint must be clean
- Types must be correct
- Tests must pass
- Build must succeed

If any gate fails: Fix ‚Üí Re-run ‚Üí Repeat until pass

Do NOT treat validation as optional. These are blocking requirements.
---

## Input
The user will provide the path to a specification file (e.g., `spec/auth/spec.md`).

**IMPORTANT**: Before planning, you must:
1. Read `spec/README.md` for workflow philosophy
2. Assess complexity and scope
3. Ask mandatory clarifying questions
4. Wait for confirmation before generating detailed plan

## Process

1. **Load Philosophy**
   - **First: Read `spec/README.md`** to understand workflow standards
   - This ensures consistency with project methodology

2. **Cleanup Shipped Features** (Optional Pre-planning)

   **Recommended workflow**:

   Before running `/plan`, you may want to clean up shipped features:

   **Option A: Automatic cleanup** (Solo devs):
   - Run `/cleanup` after merging a PR
   - Creates `cleanup/merged` branch with specs deleted
   - `/plan` will detect and rename this branch to `feature/new-name`

   **Option B: Manual cleanup** (Team conventions):
   - Manually delete merged branches: `git branch -d feature/old`
   - Manually delete shipped specs: `rm -rf spec/old-feature/`
   - Checkout main before running `/plan`

   **Option C: Skip cleanup** (Works fine):
   - Run `/plan` from main without cleanup
   - Old specs remain (harmless, preserved in git)
   - `/plan` creates new feature branch as usual

   **Note**: Specs are NOT moved to `spec/archive/`. When deleted, they're preserved in git history. `SHIPPED.md` provides the reference to find them.

3. **Read and Understand Specification**
    - Read the specification file completely
    - Extract: desired outcome, constraints, examples, validation criteria, success metrics
    - Identify any ambiguous requirements and note them

4. **COMPLEXITY ASSESSMENT** (MANDATORY GATE)

   Calculate complexity score (0-10) based on:

   **File Impact**:
   - Files to create: 1-3 (1pt), 4-6 (2pts), 7-10 (3pts), 11+ (4pts)
   - Files to modify: 0-2 (0pts), 3-5 (1pt), 6-10 (2pts), 11+ (3pts)

   **Subsystem Coupling**:
   - 1 subsystem (0pts), 2 subsystems (1pt), 3 subsystems (2pts), 4+ (3pts)

   **Task Estimate**:
   - < 8 subtasks (1pt), 8-12 (2pts), 13-18 (3pts), 19+ (4pts)

   **Dependencies**:
   - 0-1 new packages (0pts), 2-3 (1pt), 4+ (2pts)

   **Pattern Novelty**:
   - Existing patterns (0pts), Adapting patterns (1pt), New patterns (2pts)

   **Total Score Interpretation**:
   - **0-5: Proceed** ‚úÖ Well-scoped feature
   - **6-10: Split** üõë Recommend splitting or explicit override

   **If Score >= 6 ‚Üí RECOMMEND SPLIT**:

   Present complexity breakdown:
   ```
   üõë COMPLEXITY: {score}/10 (HIGH - SPLIT RECOMMENDED)

   **Complexity Factors**:
   üìÅ File Impact: Creating {N} files, modifying {M} files ({total} files)
   üîó Subsystems: Touching {N} subsystems (list: UI, API, Database, etc.)
   üî¢ Task Estimate: ~{N} subtasks
   üì¶ Dependencies: {N} new packages (list them)
   üÜï Pattern Novelty: {existing/adapting/new}

   **Why This Is Risky**:
   - Context overload: {N} subtasks is difficult to track and debug
   - Validation isolation: Hard to isolate which of {N} steps caused failure
   - PR review difficulty: {total} files is unreviewable in single PR
   - Architectural pivot cost: If approach is wrong, significant time wasted
   - Token limit risks: Large context may hit AI limits

   **You know this feeling**:
   - Hour 1: "This is going great!"
   - Hour 3: "Wait, why is this test failing?"
   - Hour 5: "Which of the {N} changes broke this?"
   - Hour 6: "I should have split this up..."

   **RECOMMENDATION: SPLIT INTO PHASES**

   Generate phase breakdown? (y/n)
   ```

   **If user answers y - Show detailed breakdown**:
   ```
   ### Phase 1: {Name} (Complexity: {score}/10) ‚úÖ
   **Start here** - {Why this first}
   {Scope bullets}
   **Estimated**: {N} subtasks
   **Can ship**: {Yes/No} - {Why}

   ### Phase 2: {Name} (Complexity: {score}/10) ‚ö†Ô∏è
   **Do second** - {Why this second}
   {Scope bullets}
   **Estimated**: {N} subtasks
   **Can ship**: {Yes/No} - {Why}

   ### Phase 3: {Name} (Complexity: {score}/10) ‚ö†Ô∏è
   **Do last** - {Why this last}
   {Scope bullets}
   **Estimated**: {N} subtasks
   **Can ship**: {Yes/No} - {Why}

   **Why Splitting Works**:
   ‚úÖ Each phase has meaningful validation gates (< 13 subtasks = debuggable)
   ‚úÖ Ship Phase 1, get feedback, adjust Phase 2 accordingly
   ‚úÖ PRs are reviewable size (Phase 1 = ~{N} files vs {total} files)
   ‚úÖ If Phase 1 reveals issues, haven't wasted time on Phase 2/3
   ‚úÖ Incremental value delivery

   **Your Decision** (required):
   1. **Phase 1 only** - Generate full spec for Phase 1 (recommended)
   2. **Full roadmap** - Generate Phase 1 spec + Phase 2/3 outlines
   3. **Proceed with full scope** - Override split recommendation

   Please choose: 1, 2, or 3
   ```

   **If user answers n - Skip to decision**:
   ```
   **Your Decision** (required):
   1. **Split into phases** - I'll help break this down (recommended)
   2. **Proceed with full scope** - Override split recommendation

   Please choose: 1 or 2
   ```

   **If User Chooses split (from either path)**:
   [Continue with phase planning...]

   **If User Chooses override (option 3 from detailed, option 2 from simple)**:
   ```
   ‚ö†Ô∏è Override split recommendation?

   Complexity: {score}/10 (HIGH)
   Risk: {N} subtasks, {total} files, multiple subsystems

   Proceed with full scope anyway? (y/n)
   ```

   **If user answers y**:
   ```
   ‚úÖ Proceeding with full-scope plan

   Mitigation: Commit after every 3-5 subtasks, run validation gates frequently.

   Generating comprehensive plan...
   ```

   **If user answers n**:
   ```
   Returning to phase selection. Choose 1 or 2.
   ```

   **If Score 0-5 (Proceed)**:
   ```
   ‚úÖ COMPLEXITY: {score}/10

   Well-scoped feature. Proceeding to planning.
   ```

   **WAIT FOR USER DECISION**

5. **Ask Mandatory Clarifying Questions** (REQUIRED GATE)

   **CRITICAL**: You MUST ask clarifying questions before generating the plan.

   **Do NOT skip this step**. Even if the spec seems clear, ask about:
   - Ambiguous requirements or undefined behaviors
   - Integration points not explicitly stated
   - Technical tradeoffs (performance vs simplicity, etc.)
   - Existing patterns to follow or avoid
   - Edge cases not covered in spec
   - Testing strategy and coverage expectations
   - Error handling approach

   **Format Requirements**:
   - Use numbered/lettered lists for easy responses
   - Group related questions by category
   - Provide multiple-choice options where applicable (A/B/C choices)
   - Make it easy for user to respond with "1a, 2, 3b" style answers

   **Example template**:
   ```
   Before I create the implementation plan, I need clarification on:

   **Requirements**:
   1. {Specific ambiguous requirement from spec}
      a) Option A: {interpretation}
      b) Option B: {alternative interpretation}
   2. {Question about scope boundary}

   **Technical Approach**:
   3. Should this follow the pattern in {similar-feature at path/to/file.ts}?
      a) Yes, mirror that approach
      b) No, use different pattern because {reason}
   4. What's the priority tradeoff:
      a) Performance (faster but more complex)
      b) Simplicity (cleaner code but potentially slower)
      c) Balance both

   **Integration**:
   5. How should this integrate with {existing-system}?
   6. Should we modify {existing-component} or create new one?

   **Edge Cases**:
   7. How should we handle {edge case scenario}?
      a) {Option A}
      b) {Option B}
   8. What's the expected behavior when {error condition}?

   **Testing**:
   9. What test coverage level is expected?
      a) Unit tests only
      b) Unit + Integration tests
      c) Unit + Integration + E2E tests
   10. Are there specific test scenarios you want covered?
   ```

   **WAIT FOR USER RESPONSES**

   Incorporate all answers into the plan before proceeding to codebase research.

6. **Research Codebase**
    - Search for similar patterns/features already implemented
    - Identify files that will need modification
    - Find relevant test patterns to follow
    - Note architectural decisions that impact implementation

7. **External Research** (if needed)
    - Search for library documentation
    - Find best practices for the specific technology
    - Identify common pitfalls and their solutions

8. **ULTRATHINK: Synthesize All Context into Coherent Plan**

   **CRITICAL**: Before creating the plan, think deeply about everything you've learned.

   **You now have**:
   - The spec requirements and constraints
   - User answers to clarifying questions
   - Existing codebase patterns you found
   - External research and best practices
   - Complexity assessment and scope decision

   **Spend time analyzing**:
   - What is the SIMPLEST approach that meets all requirements?
   - Which existing patterns should I follow vs adapt vs avoid?
   - What are the critical path dependencies between tasks?
   - Where are the highest-risk areas that need extra validation?
   - What will trip up the implementation? (Common pitfalls from research)
   - What context from research is essential to include in the plan?

   **Ask yourself**:
   - If I were implementing this myself, what would I want to know?
   - What patterns did I find that make this easier?
   - What gotchas from external research should I warn about?
   - Are there any circular dependencies in my task breakdown?
   - What's the atomic unit of work that can be validated independently?
   - What would cause this plan to fail? How do I mitigate?

   **Synthesis goal**: Create a plan that enables autonomous implementation by:
   - Providing concrete patterns to follow (with file paths and line numbers)
   - Breaking down into validatable atomic tasks
   - Including critical context from research
   - Anticipating and documenting pitfalls
   - Enabling incremental progress with clear validation gates

   **Red flags to check**:
   - ‚ùå Tasks are vague ("implement feature X") - need concrete steps
   - ‚ùå No reference to existing code patterns - plan will be generic
   - ‚ùå Tasks depend on each other in unclear ways - will cause confusion
   - ‚ùå No validation criteria per task - can't verify progress
   - ‚ùå Missing context from research - will repeat known mistakes

   **Output from this step**: Clear mental model of implementation approach, task sequencing, and validation strategy.

9. **Create Implementation Plan**
   Save to `spec/{feature}/plan.md`:

   ```markdown
   # Implementation Plan: {Feature Name}
   Generated: {timestamp}
   Specification: spec.md

   ## Understanding
   {AI's interpretation of the requirements}

   ## Relevant Files

   **Reference Patterns** (existing code to follow):
   - `{path/to/similar-feature.ts}` (lines {X-Y}) - {what pattern to follow}
   - `{path/to/another-example.ts}` (lines {X-Y}) - {specific technique}
   - `{path/to/test-example.test.ts}` - {test pattern to mirror}

   **Files to Create**:
   - `{path/to/new-component.tsx}` - {purpose and responsibility}
   - `{path/to/new-service.ts}` - {purpose and responsibility}
   - `{path/to/new-test.test.ts}` - {test coverage scope}

   **Files to Modify**:
   - `{path/to/existing.ts}` (lines ~{X-Y}) - {what changes and why}
   - `{path/to/config.ts}` (add {what}) - {purpose of addition}
   - `{path/to/routes.ts}` (integrate {what}) - {integration approach}

   ## Architecture Impact
   - **Subsystems affected**: {list: e.g., UI, API, Database, Auth}
   - **New dependencies**: {if any - list package names and versions}
   - **Breaking changes**: {if any - describe impact}

   ## Task Breakdown
   ### Task 1: {Name}
   **File**: {path/to/file.ts}
   **Action**: CREATE | MODIFY
   **Pattern**: Reference {path/to/similar.ts} lines {X-Y}
   
   **Implementation**:
   ```typescript
   // Pseudocode showing approach
   ```

   **Validation**:
   Use validation commands from `spec/stack.md`

   ### Task 2: {...}

   ## Risk Assessment
    - **Risk**: {Description}
      **Mitigation**: {Strategy}

   ## Integration Points
    - Store updates: {which stores, what changes}
    - Route changes: {if applicable}
    - Config updates: {constants, env vars}

   ## VALIDATION GATES (MANDATORY)

   **CRITICAL**: These are not suggestions - they are GATES that block progress.

   After EVERY code change, use commands from `spec/stack.md`:
   - Gate 1: Syntax & Style (lint command)
   - Gate 2: Type Safety (typecheck command)
   - Gate 3: Unit Tests (test command)

   **Enforcement Rules**:
   - If ANY gate fails ‚Üí Fix immediately
   - Re-run validation after fix
   - Loop until ALL gates pass
   - After 3 failed attempts ‚Üí Stop and ask for help

   **Do not proceed to next task until current task passes all gates.**

   ## Validation Sequence
   After each task: Use lint, typecheck, and test commands from `spec/stack.md`

   Final validation: Run full test suite and build command from `spec/stack.md`

   ## Plan Quality Assessment

   **Complexity Score**: {score}/10 ({LOW/MEDIUM-LOW/MEDIUM-HIGH/HIGH/CRITICAL})
   **Confidence Score**: {score}/10 ({LOW/MEDIUM/HIGH})

   **Confidence Factors**:
   ‚úÖ Clear requirements from spec
   ‚úÖ Similar patterns found in codebase at {paths}
   ‚úÖ All clarifying questions answered
   ‚úÖ Existing test patterns to follow at {paths}
   ‚ö†Ô∏è New pattern - no existing reference
   ‚ö†Ô∏è External dependency uncertainty ({package-name})
   ‚ö†Ô∏è Multiple subsystem integration required
   üõë Critical risk: {description}

   **Assessment**: {One sentence summary of implementation confidence}

   **Estimated one-pass success probability**: {percentage}%

   **Reasoning**: {Brief explanation of confidence score based on factors above}
   ```

10. **Git Setup**

   After generating the plan, run the git setup workflow via `scripts/plan.sh`:

   The script handles:
   - **Branch creation/renaming**:
     - If on `cleanup/merged`: Renames to `feature/$feature_name` (solo dev fast path)
     - If on `main`/`master`: Creates `feature/$feature_name` branch
     - If on `feature/$feature_name`: Continues (already on correct branch)
     - If on different feature branch: Errors and suggests options
     - If on unknown branch: Prompts for confirmation
   - **Committing planning artifacts**: Stages and commits spec.md and plan.md

   Call via csw:
   ```bash
   csw plan "$spec_file"
   ```

   **Branch Convention**:
   - `cleanup/merged` - Magic branch from `/cleanup` command (gets renamed)
   - `feature/*` - Active feature development
   - `main`/`master` - Clean starting point

## Output Format
Report to user:
```
‚úÖ Implementation plan created for {feature}
üìÅ Location: spec/{feature}/plan.md
üåø Branch: feature/{feature-name}

üìä ASSESSMENT:
   Complexity: {score}/10 ({LOW/MEDIUM/HIGH/CRITICAL})
   Confidence: {score}/10 ({LOW/MEDIUM/HIGH})
   One-pass success probability: {percentage}%

üìã Tasks: {N} identified
‚ö° Ready to build: /build spec/{feature}/
```

## Error Handling
- If spec file missing: Report error with path tried
- If ambiguous requirements: List them and ask for clarification
- If architectural concerns: Highlight them prominently in risks

## Execution

```bash
# Try csw in PATH first, fall back to project-local wrapper
if command -v csw &> /dev/null; then
    csw plan "$SPEC_FILE"
elif [ -f "./spec/csw" ]; then
    ./spec/csw plan "$SPEC_FILE"
else
    echo "‚ùå Error: csw not found"
    echo "   Run install.sh to set up csw globally"
    echo "   Or use: ./spec/csw plan (if initialized)"
    exit 1
fi
```